---
title: "Descomposición de series de tiempo"
author: "Pablo Benavides Herrera"
date: 2020-02-28
output:
  html_notebook:
    toc: yes
    toc_float: yes
    theme: cerulean
    highlight: tango
  github_document:
    toc: yes
    dev: jpeg
---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(echo= TRUE,
                      fig.height = 6, fig.width = 7)
```

Como hemos visto, las series de tiempo pueden presentar varios patrones, y comúnmente es útil dividir o descomponer la serie en cada uno de esos patrones. Recordando, una serie de tiempo puede exhibir:

-   Tendencia
-   Estacionalidad
-   Ciclos

Al realizar la descomposición de la serie, usualmente se juntan el patrón cíclico y la tendencia en uno solo, llamado simplemente **tendencia**. Así, tendríamos tres componentes en una serie de tiempo cualquiera:

1.  Tendencia
2.  Estacionalidad
3.  Residuo (lo que no es parte ni de la tendencia, ni del efecto estacional)

# Transformaciones y ajustes

Ahora, lo que buscamos es analizar datos lo más sencillos posibles, por lo que en ocasiones vale la pena llevar a cabo *transformaciones* o *ajustes* de la serie de tiempo. Vamos a revisar cuatro tipos: ajustes de calendario, por población, inflacionarios y transformaciones matemáticas.

### Ajustes de calendario

Parte de la variación en las series de tiempo puede deberse a efectos muy sencillos que tienen que ver con el calendario. Algunos ejemplos de esto pueden ser variaciones en datos mensuales, debido a la cantidad de días hábiles en cada mes. Tomemos el caso del volumen de transacciones de Alphabet Inc., holding de Google, entre otras.

```{r ajuste calendario google, message=FALSE, warning=FALSE, results='hide'}
library("easypackages")
packages("tidyverse", "tidyquant", "lubridate", "patchwork", "fpp2","fpp3","scales", "timetk")

transacciones_mensuales <- tq_get("GOOG", get = "stock.prices",
                                  from = "2015-01-01") %>%
  summarise_by_time(
    .date_var      =  date, 
    .by            = "month",
    monthly_volume = sum(volume),
    trading_days   = n(),
    mean_volume    = mean(volume)) %>%
  mutate(month     = yearmonth(date)) %>% 
  select(month, everything(), -date) %>% 
  as_tsibble(index = month)

transacciones_mensuales

# en vez de "summarise_by_time" se pudo haber hecho esto:

# group_by(month = floor_date(date, "month")) %>%
#   summarise(monthly_volume = sum(volume),
#             trading_days = n(),
#             mean_volume = mean(volume)) %>%
#   mutate(month = yearmonth(date)) %>% select(month,-date, monthly_volume:mean_volume) %>% 
#   as_tsibble(index = month)
```

```{r}
gamestop <- tq_get("GME", from = "2018-01-01")
gamestop

gamestop %>% 
  as_tsibble(index = date, key = symbol) %>% 
  autoplot(volume)
```

Podemos graficar ambas con dos (o más) alternativas: cada variable por separado y unirlas con `patchwork`, o utilizar `pivot_longer()` y `facet_wrap()`.

```{r}
# Opción 1
p1 <- ggplot(data = transacciones_mensuales) + 
  geom_line(aes(x = month, y = monthly_volume)) +
  ylab("Vol. total mensual") + 
  xlab("")

p2 <- ggplot(data = transacciones_mensuales) + 
  geom_line(aes(x = month, y = mean_volume)) +
  ylab("Vol. promedio diario") +
  xlab("")

p1 / p2
# Opción 2

transacciones_mensuales %>% 
  pivot_longer(cols = c(monthly_volume, mean_volume),
               names_to = "variable", values_to = "valor") %>% 
  ggplot(aes(x = month, y = valor)) +
  geom_line() + ylab("Transacciones") + xlab("") +
  facet_wrap(~ variable, ncol = 1, scales = "free_y")
```

```{r}
p <- global_economy %>% 
  filter(Country == "Mexico") %>% 
  pivot_longer(cols = -c(Country:Year)) %>% 
  ggplot(aes(x = Year, y = value)) +
  geom_line() + facet_wrap(~ name, scales = "free_y")

plotly::ggplotly(p)
```

La serie original tomando el total de transacciones mensuales presenta mayor variación que cuando ajustamos la serie por los dias calendario (llegando al volumen promedio diario).

### Ajustes poblacionales

Cualquier variable que se ve afectada por la población, puede ser expresada en términos *per cápita*. Si, p. ej., con la pandemia del COVID-19, se quisiera analizar la cantidad de médicos laborando en México y ver su evolución histórica, tomar únicamente la cantidad de médicos podría ser engañoso, si no se toma en consideración el crecimiento de la población. Así, sería más recomendable observar la variable de cantidad de *médicos por cada 100 mil habitantes*, por ejemplo, para ver si la cantidad de médicos ha aumentado, se ha mantenido estable o ha disminuido a lo largo del tiempo.

Otro ejemplo que se puede analizar es el del PIB de los países. Tomemos tres casos: México, Australia e Islandia. Si consideramos el PIB para ver qué tan bien se ha comportado la economía de cada uno de los países, veríamos el siguiente efecto:

```{r countries gdp}
glimpse(global_economy)

ge <- global_economy %>% 
  filter(Country == "Mexico" | Country == "Iceland" | Country == "Australia")
  # filter(Country %in% c("Mexico", "Iceland", "Australia"))

p3 <- ggplot(ge) + aes(x = Year, y = GDP, color = Country) + 
  geom_line()
 
p3
```

¿Realmente creen que la economía de México esté a la par de la economía de Australia e, incluso, muy superior a la de Islandia?

Lo cierto es que no. La variable del PIB no está considerando la población de cada país; México tiene una población mucho mayor que la de los otros dos países:

```{r countries population}
ggplot(ge) + aes(x = Year, y = Population, color = Country) +
  geom_line()
```

Ahora, si ajustamos los datos del PIB para tomar en cuenta la población, obtendríamos el **PIB per cápita**.

```{r countries gdp per capita}
p4 <- ggplot(ge) + aes(x = Year, y = GDP / Population, color = Country) +
  geom_line() + ylab("GDP per capita")

p4
```

Aquí queda claro que la economía de Australia e Islandia es bastante superior a la mexicana (lo producido en México por persona es mucho menor que lo producido por persona en Australia e Islandia).

### Ajustes inflacionarios

Los datos afectados por el valor del dinero en el tiempo se deben ajustar antes de modelarse. Esto se debe a la inflación: sus abuelos podían comprar una coca y un gansito tal vez con menos de 3 pesos. ¿Cuánto dinero necesitarían hoy para comprar una coca y un gansito? Entonces, las series de tiempo financieras se ajustan a la inflación, y se expresan en términos de alguna moneda constante (en el tiempo). Por ejemplo, se puede medir el valor de la vivienda en Gudalajara, con precios constantes de 2010 (imaginando que no hubiera cambiado el valor del dinero en el tiempo).

Para realizar el ajuste inflacionario, se toma un índice de precios. Si }$z_t$ es el índice de precios y $y_t$ es el valor original de la vivienda en el tiempo $t$, entonces el precio de la vivienda, $x_t$, ajustado a valor del año 2010, estaría dado por:

$$
x_t = \frac{y_t}{z_t} * z_{2010}
$$ Los índices de precios son construidos, generalmente, por el gobierno, o alguna dependencia de gobierno. En México, el más común es el Índice Nacional de Precios al Consumidor (INPC), que es construido por el INEGI.

Veamos el caso de la industria de periódicos y libros impresos en Australia y su crecimiento o decrecimiento en el tiempo. Tomaremos los datos de `aus_retail` y ajustaremos la inflación con el índice de precios al consumidor, `CPI`, dentro de la tabla `global_economy`.

```{r inflation adjusted printing industry, message=TRUE, warning=TRUE}
print_retail <- aus_retail %>%
  filter(Industry == "Newspaper and book retailing") %>%
  group_by(Industry) %>%
  index_by(Year = year(Month)) %>%
  summarise(Turnover = sum(Turnover))

autoplot(print_retail)

aus_economy <- global_economy %>%
  filter(Code == "AUS")
  # filter(Country == "Australia")

print_retail %>% 
  # unir las tablas print_retail y aus_economy con base en
  # print_retail
  left_join(aus_economy, by = "Year") %>%
  # calculando las ventas sin inflación
  mutate(Adjusted_turnover = Turnover / CPI) %>%
  #
  pivot_longer(
    cols            = c(Turnover, Adjusted_turnover),
    names_to        = "Type",
    values_to       = "Turnover",
    names_transform = list(Type = as_factor) 
  ) %>% 
  # gather es la versión vieja de pivot_longer, por lo tanto ya
  # no se recomienda utilizar
  # gather("Type", "Turnover", Turnover, Adjusted_turnover, factor_key = TRUE) %>%
  ggplot(aes(x = Year, y = Turnover)) +
    geom_line() +
    facet_grid(vars(Type), scales = "free_y") +
    xlab("Years") + ylab(NULL) +
    ggtitle("Turnover for the Australian print media industry")
```

Al ver los datos ajustados, nos percatamos de que la venta de estos productos impresos ha decaído mucho más de lo que los datos sin ajustar sugieren.

### Transformaciones matemáticas

Si los datos presentan variación que aumenta o disminuye con el nivel de la serie, se puede sugerir una transformación matemática. Las **transformaciones logarítmicas** son muy utilizadas. Una de las razones es porque son fácilmente interpretables: los cambios en el valor logarítmico son relativos (o porcentuales), a cambios en la escala original. Una desventaja de la transformación logarítmica, es que no se puede utilizar con valores iguales a cero o negativos.

Recordando clases anteriores, donde teníamos las ventas trimestrales de J&J. Se observa que la variación aumenta con el nivel de la serie. Asimismo, parece tener una forma exponencial.

```{r jj Q sales}
data("JohnsonJohnson")
autoplot(JohnsonJohnson)+
  ggtitle("Ventas trimestrales de J&J")
```

Podemos probar aplicando una transformación logarítmica a los datos para ver si logramos hacer que la variación sea uniforme a lo largo del tiempo, y ver si podemos hacer que parezca tener una tendencia lineal.

```{r log jj}
autoplot(log(JohnsonJohnson)) +
  ggtitle("Logaritmo de las ventas trim. de J&J")
```

Otro tipo de transformaciones matemáticas son las **transformaciones de potencia**. P. ej., sacar la raíz cuadrada o cúbica de los datos, etc. Estas transformaciones se pueden escribir como $w_t = y_t^p$.

```{r}
autoplot(JohnsonJohnson^(1/3)) +
  ggtitle("Logaritmo de las ventas trim. de J&J")
```

Una familia de transformaciones matemáticas que incluye, tanto logaritmos, como potencias son las **transformaciones Box-Cox**, que dependen de un parámetro, $\lambda$ y se definen de la siguiente manera:

$$w_{t}=\left\{\begin{array}{ll}
\log \left(y_{t}\right) & \text { si } \lambda=0 \\
\left(y_{t}^{\lambda}-1\right) / \lambda & \text { en otro caso }
\end{array}\right.$$

Aquí, el logaritmo siempre es un logaritmo natural. Si $\lambda = 0$, se utiliza un logaritmo natural, de lo contrario se utiliza una potencia, con un escalado simple.

Si $\lambda = 1$ entonces $w_t = y_t-1$, lo que significaría que los datos solo se desplazarían hacia abajo, sin cambiar la forma de la serie de tiempo. Para cualquier otro valor de $\lambda$, la serie cambiará de forma.

*¿Cómo escoger el valor de* $\lambda$ a utilizar?

Un buen valor de $\lambda$ es aquel que hace que el tamaño de la variación estacional sea el mismo a lo largo de la serie, para que el modelado y pronóstico sea más sencillo.

Para ejemplificar esto, tomemos datos sobre la producción de gas en Australia.

```{r box cox transform}
p5a <- aus_production %>% autoplot(Gas)+ 
  ggtitle("Producción de gas (datos reales)")

p5 <- aus_production %>% autoplot(box_cox(Gas,lambda = -0.5)) + ggtitle("Box-Cox, lambda = -0.5")

p6 <- aus_production %>% autoplot(box_cox(Gas,lambda = 0)) + ggtitle("Box-Cox, lambda = 0 (log)")

p7 <- aus_production %>% autoplot(box_cox(Gas,lambda = 0.1)) + ggtitle("Box-Cox, lambda = 0.1")

p8 <- aus_production %>% autoplot(box_cox(Gas,lambda = 1)) + ggtitle("Box-Cox, lambda = 1")

p5a

(p5 | p6) / (p7 | p8)
```

```{r box-cox shiny, include=FALSE}
# sliderInput("lambda",
#   label = "Selecciona el valor de lambda: ",
#   min = -1, max = 2, value = 0,
#   step = 0.1, animate = F
# )
# 
# renderPlot({
#   aus_production %>% 
#     autoplot(box_cox(Gas,lambda = input$lambda)) + ggtitle("Transformaciones de Box-Cox")
# })
```

La característica de `guerrero` nos ayuda a seleccionar un valor de $\lambda$. En este caso, escogió un $\lambda = 0.12$

```{r box cox guerrero feature}
(lambda <- aus_production %>%
  features(Gas, features = guerrero) %>%
  pull(lambda_guerrero))

aus_production %>% autoplot(box_cox(Gas, lambda))
```

# Componentes de las series de tiempo

Si empleamos una **descomposición aditiva**, se podría explicar a nuestra serie de tiempo, $y_t$ como:

$$
y_t = S_t + T_t + R_t
$$

Donde $S_t$ representa el componente estacional, $T_t$ la tendencia-ciclo y $R_t$ el residuo. Una **descomposición multiplicativa** tomaría la forma:

$$
y_t = S_t * T_t * R_t
$$

*¿Cuándo utilizar la descomposición aditiva y cuándo la multiplicativa?*

La aditiva es mejor cuando la magnitud de la fluctuación estacional no cambia con el nivel de la serie. Por el contrario, cuando la variación del componente estacional cambia a lo largo del tiempo, se recomendaría utilizar la multiplicativa. Esta última es muy común en series de tiempo económicas.

Una alternativa para no utilizar la descomposición multiplicativa es transformar los datos para evitar la fluctuación en la variación y posteriormente aplicar la aditiva. De hecho, si se aplica una transformación logarítmica a los datos, es equivalente a utilizar una descomposición multiplicativa, porque:

$$y_{t}=S_{t} \times T_{t} \times R_{t} \quad \text { es equivalente a } \quad \log y_{t}=\log S_{t}+\log T_{t}+\log R_{t}$$ Veamos el ejemplo del empleo en el sector de las ventas al menudeo en EEUU desde 1990.

```{r retail employment}
us_retail_employment <- us_employment %>%
  filter(year(Month) >= 1990, Title == "Retail Trade") %>%
  select(-Series_ID)

us_retail_employment

us_retail_employment %>%
  autoplot(Employed) +
  xlab("Year") + ylab("Persons (thousands)") +
  ggtitle("Total employment in US retail")
```

Vamos a llevar a cabo un tipo de descomposición llamado **STL** (que analizaremos con mayor detalle posteriormente).

```{r STL decomp tbl, paged.print=FALSE}
dcmp <- us_retail_employment %>%
  model(Descomposicion = STL(Employed))

components(dcmp)
```

Estos comandos llevan a cabo la descomposición de la serie, como se puede ver en la tabla. La tendencia, `trend` muestra el movimiento de la serie, sin considerar las fluctuaciones estacionales ni el residuo. Podemos analizar la tendencia de la serie gráficamente:

```{r employment trend}
us_retail_employment %>%
  autoplot(Employed, color='gray') +
  autolayer(components(dcmp), trend, color='red') +
  xlab("Year") + ylab("Persons (thousands)") +
  ggtitle("Total employment in US retail")
```

Podemos graficar los tres componentes simultáneamente con:

```{r STL decomp plot}
p <- components(dcmp) %>% autoplot() + xlab("Year")
plotly::ggplotly(p)

components(dcmp) %>% 
  as_tibble() %>% 
  mutate(Month = as.Date(Month)) %>% 
  filter(Month >= "2018-01-01") %>% 
  ggplot(aes(x = Month, y = Employed)) +
  geom_line() + xlab("Year") +
  scale_x_date(date_breaks = "1 month", date_labels = "%b %y") +
  theme(axis.text.x = element_text(angle = 90))
```

La gráfica nos indica que se llevó a cabo una descomposición STL, de forma aditiva, y nos grafica:

1.  La serie original.
2.  La tendencia.
3.  El componente estacional.
4.  El residuo.

Si se suma cada uno de los componentes, obtenemos la serie original.

Las barras grises en estas gráficas indican las escalas relativas de los componentes.

### Datos desestacionalizados

En ocasiones, los datos presentados por el gobierno u otra organización se dice que están **desestacionalizados**. Esto significa que le quitaron el componente estacional a la serie. Si se quita, los datos ahora están "ajustados estacionalmente". Para la descomposición aditiva, los datos destacionalizados están dados por $y_t - S_t$, mientras que en la multiplicativa estarían dados por $\frac{y_t}{S_t}$. Veamos los datos del empleo, desestacionalizados:

```{r employment seasonally adjusted}
us_retail_employment %>%
  autoplot(Employed, color='gray') +
  autolayer(components(dcmp), season_adjust, color='blue') +
  xlab("Year") + ylab("Persons (thousands)") +
  ggtitle("Total employment in US retail")
```

Si la variación debido a la estacionalidad no es de interés en particular, los datos desestacionalizados pueden ser muy útiles. Un ejemplo común es el nivel de desempleo o crecimiento económico. El INEGI reporta las cifras de manera desestacionalizadas. Esto nos permite ver el estado de la economía, sin tomar en cuenta factores estacionales.

# Medias móviles

La descomposición de series de tiempo clásica utilizaba medias móviles para definir el componente de tendencia.

Así, una suavización de media móvil de orden $m$ estaría dada por:

$$
\hat{T}_{t}=\frac{1}{m} \sum_{j=-k}^{k} y_{t+j}
$$ en donde $m = 2k +1$. Entonces, el estimado de de la tendencia en el periodo $t$, $\hat{T}_t$, se obtiene al promediar los valores de la serie de tiempo dentro de los $k$ periodos alrededor de $t$. A esto se le llama una media móvil de orden $m$; $m$-**MA**.

```{r mex exports plot}
p <- global_economy %>%
  filter(Country == "Mexico") %>%
  autoplot(Exports) +
  xlab("Year") + ylab("% of GDP") +
  ggtitle("Total Mexican exports")

plotly::ggplotly(p)
```

En la gráfica tenemos las exportaciones de México desde 1960 a 2017, como porcentaje del PIB. Podemos calcular una media móvil de orden 5; esto es, obtener el promedio de 5 periodos, para cada momento, $t$, con el centro de la "ventana" en $t$. Así, de acuerdo a la ecuación presentada, $k = 2$ y $m = 2k +1 = 5$.

```{r 5-MA}
mex_exports <- global_economy %>%
  filter(Country == "Mexico") %>%
  mutate(
    `5-MA` = slider::slide_dbl(Exports, mean, 
                               .before   = 2, 
                               .after    = 2,
                               .complete = TRUE)
  )

mex_exports
```

Para ver cómo se presenta esta media móvil gráficamente, podemos hacer lo siguiente:

```{r 5-MA plot, warning=FALSE}
gg <- mex_exports %>%
  ggplot(aes(x = Year, y = Exports)) + 
  geom_line() +
  xlab("Year") + ylab("Exports (% of GDP)")
  
gg + geom_line(aes(y = `5-MA`), color='red') +
  ggtitle("Total Mexican exports & 5-MA")

# Se logra lo mismo con autoplot() y autolayer()
mex_exports %>% 
  autoplot(Exports) + 
  autolayer(mex_exports, `5-MA`, color = "red") +
  xlab("Year") + ylab("Exports (% of GDP)") +
  ggtitle("Total Mexican exports & 5-MA")
```

Se puede ver que la tendencia es mucho más suave que los datos originales, captura el movimiento principal de la serie, pero deja de lado las fluctuaciones intermedias o menores.

Qué tan suave esté la curva resultante, dependerá del orden de la media móvil.

```{r m-MA plots, fig.height=8,fig.width=12, warning=FALSE}
mex_exports <- mex_exports %>%
  mutate(
    `1-MA` = slider::slide_dbl(Exports, mean, 
                               .before = 0, 
                               .after = 0, .complete = TRUE),
    `3-MA` = slider::slide_dbl(Exports, mean, 
                               .before = 1, 
                               .after = 1, .complete = TRUE),
    `7-MA` = slider::slide_dbl(Exports, mean, 
                               .before = 3, 
                               .after = 3, .complete = TRUE),
    `9-MA` = slider::slide_dbl(Exports, mean, 
                               .before = 4, 
                               .after = 4, .complete = TRUE),
    `11-MA` = slider::slide_dbl(Exports, mean, 
                                .before = 5, 
                                .after = 5, .complete = TRUE),
    `15-MA` = slider::slide_dbl(Exports, mean, 
                                .before = 7, 
                                .after = 7, .complete = TRUE),
    `17-MA` = slider::slide_dbl(Exports, mean, 
                                .before = 8, 
                                .after = 8, .complete = TRUE),
    `21-MA` = slider::slide_dbl(Exports, mean, 
                                .before = 10, 
                                .after = 10, .complete = TRUE)
  )

gg <- mex_exports %>%
  ggplot(aes(x = Year, y = Exports)) + 
  geom_line() +
  xlab("Year") + ylab("Exports (% of GDP)")

g1 <- gg +
 geom_line(aes(y = `1-MA`), color='red') +
  ggtitle("1-MA")
g3 <- gg +
 geom_line(aes(y = `3-MA`), color='red') +
  ggtitle("3-MA")
g5 <- gg +
 geom_line(aes(y = `5-MA`), color='red') +
  ggtitle("5-MA")
g7 <- gg +
 geom_line(aes(y = `7-MA`), color='red') +
  ggtitle("7-MA")
g9 <- gg +
 geom_line(aes(y = `9-MA`), color='red') +
  ggtitle("9-MA")
g11 <- gg +
 geom_line(aes(y = `11-MA`), color='red') +
  ggtitle("11-MA")
g15 <- gg +
 geom_line(aes(y = `15-MA`), color='red') +
  ggtitle("15-MA")
g17 <- gg +
 geom_line(aes(y = `17-MA`), color='red') +
  ggtitle("17-MA")
g21 <- gg +
 geom_line(aes(y = `21-MA`), color='red') +
  ggtitle("21-MA")

(g1 | g3 | g5) /
  (g7 | g9 | g11) /
  (g15 | g17 | g21)

# Graficando las 6 series de una misma vez utilizando facetas
mex_exports %>% 
  pivot_longer(
    cols      = `5-MA`:`21-MA`,
    names_to  = "Orden",
    values_to = "Media móvil"
  ) %>% 
  ggplot(aes(x = Year, y = Exports)) + 
  geom_line() + 
  geom_line(aes(y = `Media móvil`), color = "red") +
  xlab("Año") + ylab("Exportaciones (% of PIB)") +
  facet_wrap(~ Orden) +
  theme_minimal()
```

Como se puede observar, un modelo **1-MA** realmente no llevaría a cabo ninguna suavización, y un modelo **21-MA**, en este caso, se convertiría prácticamente en una línea recta.

### Medias móviles de medias móviles

A una suavización de media móvil se le puede aplicar una nueva suavización de media móvil. Por ejemplo, considerando la producción de cerveza, podemos obtener una media móvil de orden 4 y a eso sacarle la media móvil de orden 2:

```{r MA of MA, paged.print=TRUE}
beer <- aus_production %>%
  filter(year(Quarter) >= 1992) %>%
  select(Quarter, Beer)

beer_ma <- beer %>%
  mutate(
    `4-MA` = slider::slide_dbl(Beer, mean, .before = 2, .after = 1, .complete = TRUE),
    `2x4-MA` = slider::slide_dbl(`4-MA`, mean, .before = 0, .after = 1, .complete = TRUE)
  )

beer_ma
```

Al obtener la media móvil de orden 4, **4-MA**, lo que estamos haciendo es:

$$
\text{4-MA} = \hat{T}_t = \frac{1}{4}\left(y_{t-2}+y_{t-1}+y_{t}+y_{t+1}\right)
$$ y, al sacar la media móvil de orden 2 de esta media móvil, **2** $\times$ 4 - MA, sería:

$$
2 \times 4 \text{-MA} = \hat{T}_{t} = \frac{1}{2}\left[\frac{1}{4}\left(y_{t-2}+y_{t-1}+y_{t}+y_{t+1}\right)+\frac{1}{4}\left(y_{t-1}+y_{t}+y_{t+1}+y_{t+2}\right)\right]
$$ Simplificando, quedaría:

$$
2 \times 4 \text{-MA} = \hat{T}_{t} = \frac{1}{8} y_{t-2}+\frac{1}{4} y_{t-1}+\frac{1}{4} y_{t}+\frac{1}{4} y_{t+1}+\frac{1}{8} y_{t+2}
$$ Así, llegamos a ver que la media móvil de una media móvil es simplemente una **media móvil ponderada**.

### Medias móviles ponderadas

Como acabamos de ver, la combinación de dos o más medias móviles produce una media móvil ponderada. Esto es, una media móvil que depende en cierta proporción de cada rezago.

Una media móvil ponderada de orden $m$ se puede escribir como:

$$
\hat{T}_{t} = \sum_{j=-k}^{k} a_{j} y_{t+j}
$$ donde $k = (m - 1) / 2$ y los pesos o ponderaciones están dados por $\left[a_{-k}, \dots, a_{k}\right]$. La suma de los pesos debe sumar 1.

Podemos decir, entonces, que el caso de la media móvil simple $m$-MA es un caso particular de la media móvil ponderada, donde todos sus pesos son iguales a $1 / m$.

```{r 2_12MA, eval=TRUE, warning=FALSE}
us_retail_employment_ma <- us_retail_employment %>%
  mutate(
    `12-MA` = slider::slide_dbl(Employed, mean, .before = 6, .after = 5, .complete = TRUE),
    `2x12-MA` = slider::slide_dbl(`12-MA`, mean, .before = 0, .after = 1, .complete = TRUE)
  )

us_retail_employment_ma %>%
  autoplot(Employed, color='gray') +
  autolayer(us_retail_employment_ma, vars(`2x12-MA`), color='red') +
  xlab("Year") + ylab("Persons (thousands)") +
  ggtitle("Total employment in US retail, 2x12-MA")

```

$$
T_t = \frac{1}{2}\left(\frac{1}{12} ( y_{t-6} +  ) \right)
$$

# Métodos de descomposición

### Descomposición clásica

Hay dos tipos de descomposición clásica: aditiva y multiplicativa. En este tipo de descomposición, se asume que el componente estacional es constante a lo largo del tiempo.

```{r classical decomp - additive}
us_retail_employment %>%
  model(classical_decomposition(Employed, type = "additive")) %>%
  components() %>%
  autoplot() + xlab("Year") +
  ggtitle("Classical additive decomposition of total US retail employment")
```

Hoy en día, ya no se recomienda utilizar el método clásico de descomposición, ya que existen diversos métodos mejores.

Algunas de las desventajas del método clásico son las siguientes:

-   La estimación del componente de tendencia no está disponible para los primeras y últimas observaciones.

-   El componente de tendencia suele suavizar de más incrementos o caídas rápidas en los datos.

-   Asume que el componente estacional se repite año con año, por lo que no captura cambios en el patrón estacional.

### Descomposición X11

Este método funciona bastante bien con datos trimestrales y mensuales. Está basado en la descomposición clásica, pero incluye pasos adicionales para lidiar con los problemas de ella.

Así, X11 logra obtener estimadores para todos los puntos y el componente estacional puede variar ligeramente con el tiempo. También, cuenta con mecanismos para lidiar con variaciones por días calendario, efectos de días feriados, etc.

```{r X11 decomp}
x11_dcmp <- us_retail_employment %>%
  model(x11 = feasts:::X11(Employed, type = "additive")) %>%
  components()

autoplot(x11_dcmp) + xlab("Year") +
  ggtitle("Additive X11 decomposition of US retail employment in the US")
```

Podemos utilizar gráficas estacionales o gráficas de sub-series estacionales para visualizar la variación en el componente estacional a lo largo del tiempo.

```{r X11 season & subseries plot}
x11_dcmp %>% 
  gg_season()

x11_dcmp %>% 
  gg_subseries(seasonal)
```

### Descomposición SEATS

"SEATS" son las siglas de "Seasonal Extraction Arima Time Series". Este método solo funciona para datos trimestrales o mensuales. Por lo que, si se cuenta con datos de otra periodicidad, se debe implementar otro método.

```{r SEATS decomp}
seats_dcmp <- us_retail_employment %>%
  model(seats = feasts:::SEATS(Employed)) %>%
  components()
autoplot(seats_dcmp) + xlab("Year") +
  ggtitle("SEATS decomposition of total US retail employment")
```

### Descomposición STL

STL significa "Seasonal and Trend decomposition using Loess" ("Loess" es un método de estimación de relaciones no lineales).

STL tiene varias ventajas sobre los otros métodos:

-   Puede tratar con cualquier tipo de estacionalidad, no solo mensual o trimestral.

-   El componente estacional puede variar con el tiempo y el usuario decide la magnitud del cambio.

-   La suavización del componente de tendencia también es controlado por el usuario.

-   Puede ser robusto ante *outliers*, para que observaciones inusuales no afecten el componente de tendencia.

Las desventajas de este método son que no controla de manera automática la variación debido a días hábiles o variaciones por calendario. También, solo permite hacer descomposiciones aditivas.

```{r STL decomp}
us_retail_employment %>%
  model(STL(Employed ~ trend(window=7) + season(window='periodic'),
    robust = TRUE)) %>%
  components() %>%
  autoplot()

# modificando la tendencia
us_retail_employment %>%
  model(STL(Employed ~ trend(window=15) + season(window='periodic'),
    robust = TRUE)) %>%
  components() %>%
  autoplot()

# modificando la estacionalidad
us_retail_employment %>%
  model(STL(Employed ~ trend(window=7) + season(window=21),
    robust = TRUE)) %>%
  components() %>%
  autoplot()
```

Esta gráfica muestra una descomposición mediante STL, ajustando algunos parámetros (el componente de tendencia es más flexible, el componente estacional es fijo y se agregó la opción de robustez). Como muestra el código, los dos parámetros principales a seleccionar al usar STL son la tendencia, `trend(window = x)` y la estacionalidad, `season(window = y)`.

Estos parámetros controlan qué tan rápido cambian los componentes de tendencia y estacional, respectivamente. Valores más bajos provocan cambios más rápidos. **NOTA:** los valores escogidos de los parámetros deben ser impares. Si se desea mantener el mismo componente estacional a lo largo del tiempo, se debería definir como periódico, `season(window = "periodic")`, como en el caso anterior.

# Tarea

1.  Tomando el PIB de cada país, `GDP`, contenido en la tabla `global_economy`, grafique el PIB per cápita a lo largo del tiempo. ¿Cómo ha sido la evolución de la economía de los países en el tiempo? ¿Cuál país tiene el mayor PIB per cápita? (*Les recomiendo quitar la leyenda del gráfico, incluyendo `theme(legend.position = "none")`*)

```{r}
global_economy
global_economy |>
  autoplot(GDP/Population)+theme(legend.position = "none")

```

2.  Grafique las siguientes series de tiempo y transfórmelas y/o ajústelas si lo considera necesario. ¿Qué efecto tuvo la transformación?

    i)  PIB de EEUU, de `global_economy`.

    ```{r}
    unique(global_economy$Country)
    ```

```{r}
global_economy |>
  subset(Country == "United States") |>
  ggplot(aes(x = Year, y = GDP)) |
  geom_line() |
  labs(x = "Año", y = "PIB", title = "Evolución del PIB en Estados Unidos") |
  theme(legend.position = "none")
```

```{r}
# Serie transformada (por ejemplo, logaritmo natural)
global_economy |>
  subset(Country == "United States") |>
  ggplot(aes(x = Year, y = log(GDP))) |
  geom_line() |
  labs(x = "Año", y = "Log(PIB)", title = "Evolución del Logaritmo del PIB en Estados Unidos") |
  theme(legend.position = "none")
```

```         
ii) PIB de México, también de `global_economy`.
```

```{r}
# Graficar la serie de tiempo del PIB de México
global_economy |>
  subset(Country == "Mexico") |>
  ggplot(aes(x = Year, y = GDP)) |
  geom_line() |
  labs(x = "Año", y = "PIB", title = "Evolución del PIB en México") |
  theme(legend.position = "none")
```

```{r}
# Aplicar alguna transformación si es necesario
# Por ejemplo, logaritmo natural
global_economy |>
  subset(Country == "Mexico") |>
  mutate(Log_GDP = log(GDP)) |>
  ggplot(aes(x = Year, y = Log_GDP)) |
  geom_line() |
  labs(x = "Año", y = "Log(PIB)", title = "Evolución del Logaritmo del PIB en México") |
  theme(legend.position = "none")
```

```         

iii) Demanda de electricidad en el estado de Victoria (Australia), de `vic_elec`.
```

```{r}
# Graficar la serie de tiempo de la demanda de electricidad en Victoria, Australia
vic_elec |>
  ggplot(aes(x = Date, y = Demand)) |
  geom_line() |
  labs(x = "Fecha", y = "Demanda de Electricidad", title = "Demanda de Electricidad en Victoria, Australia") |
  theme(legend.position = "none")
```

3.  ¿Es útil realizar una transformación de Box-Cox a los datos `canadian_gas`? ¿Por qué sí o por qué no? \# Cargar los datos data("canadian_gas")

    ```{r}
    # Cargar los datos
    data<-data("canadian_gas")

    # Realizar la prueba de normalidad de Shapiro-Wilk
    shapiro.test(canadian_gas$Volume)
    ```

    ```{r}
    # Asegurarse de que 'data' sea un dataframe
    if (!is.data.frame(data)) {
      stop("'data' debe ser un dataframe.")
    }

    # Cargar la librería necesaria
    library(MASS)

    # Calcular la transformación de Box-Cox
    transformacion_boxcox <- boxcox(canadian_gas ~ 1, data = data)

    # Determinar el índice de lambda óptimo para la transformación
    lambda_optimo <- transformacion_boxcox$x[which.max(transformacion_boxcox$y)]

    # Aplicar la transformación de Box-Cox
    data$canadian_gas_transformada <- ifelse(lambda_optimo == 0, log(data$canadian_gas + 1), (data$canadian_gas^lambda_optimo - 1) / lambda_optimo)

    # Imprimir el índice de lambda óptimo
    print(paste("El índice de lambda óptimo para la transformación de Box-Cox es:", lambda_optimo))

    # Imprimir mensaje de éxito
    print("La variable 'canadian_gas' ha sido transformada con éxito usando la transformación de Box-Cox.")

    ```

    Para determinar si es útil realizar una transformación de Box-Cox a los datos **`canadian_gas`**, necesitamos evaluar si los datos cumplen con los supuestos de normalidad y homogeneidad de varianza. Si los datos no cumplen con estos supuestos, una transformación de Box-Cox podría ser beneficiosa para mejorar la adecuación de los datos a los modelos estadísticos.

    Para ello, podríamos seguir estos pasos:

    1.  **Prueba de normalidad**: Utilizar una prueba estadística, como la prueba de Shapiro-Wilk, para evaluar si los datos siguen una distribución normal. Si los datos no son normalmente distribuidos, una transformación de Box-Cox podría ayudar a aproximarse a la normalidad.

    2.  **Prueba de homogeneidad de varianza**: Verificar si la varianza de los datos es constante a lo largo del tiempo. Esto se puede hacer visualmente mediante un gráfico de dispersión o mediante una prueba formal, como la prueba de Bartlett o la prueba de Levene. Si la varianza no es constante, una transformación de Box-Cox podría estabilizarla.

    3.  **Aplicación de la transformación de Box-Cox**: Si los datos no cumplen con los supuestos de normalidad y homogeneidad de varianza, se puede aplicar la transformación de Box-Cox para intentar corregir estas deficiencias. La transformación de Box-Cox busca encontrar el valor de lambda que maximiza la verosimilitud de los datos transformados. Si lambda es igual a 1, implica que no es necesaria ninguna transformación; si lambda es diferente de 1, implica que se necesita una transformación.

    Sin poder realizar estos pasos directamente en este momento debido a la falta de acceso a R, te recomendaría que ejecutes estos pasos en tu entorno de R para evaluar si una transformación de Box-Cox es útil para los datos **`canadian_gas`**.

4.  El dataset `fma::plastics` tiene información de las ventas mensuales (medidas en miles) del producto A para un productor de plásticos, a lo largo de cinco años.

    i)  Grafique la serie de tiempo para el producto A. ¿Identifica algún componente de tendencia-ciclo y/o estacional?

    ```{r}
    # Cargar el paquete fma y cargar los datos
    install.packages("fma")
    library(fma)

    # Cargar los datos y asignarlos a la variable plastics
    plastics <- fma::plastics

    # Graficar la serie de tiempo del producto A
    plastics |> 
      plot(type = "l", xlab = "Tiempo", ylab = "Ventas (miles)", main = "Ventas Mensuales del Producto A")

    # Añadir una línea de tendencia para identificar posibles componentes de tendencia
    time_series <- time(plastics) # Obtener la serie de tiempo
    model <- lm(plastics ~ time_series) # Ajustar un modelo de regresión lineal
    abline(model, col = "red") # Añadir la línea de tendencia al gráfico



    ```

    ii) Utilice una descomposición clásica multiplicativa para calcular el componente de tendencia y estacional.

    ```{r}
    # Cargar los datos y asignarlos a la variable plastics
    plastics <- fma::plastics

    # Calcular la descomposición clásica multiplicativa
    decomposition <- decompose(plastics, type = "multiplicative")

    # Graficar los componentes de tendencia y estacional
    plot(decomposition)
    ```

    iii) ¿Los resultados coinciden con su respuesta al inciso i)? si

    iv) Calcule y grafique los datos desestacionalizados.

    ```{r}
    # Calcular la descomposición clásica multiplicativa

    decomposition <- decompose(plastics, type = "multiplicative")

    # Obtener los componentes de la descomposición
    trend <- decomposition$trend
    seasonal <- decomposition$seasonal
    random <- decomposition$random

    # Calcular los datos desestacionalizados
    desestacionalizado <- plastics / seasonal

    # Graficar los datos desestacionalizados
    plot(desestacionalizado, type = "l", xlab = "Tiempo", ylab = "Datos desestacionalizados",
         main = "Datos desestacionalizados del Producto A")

    ```

    v)  Cambie, manualmente, una observación para que sea un *outlier* (p. ej., sume 500 a una observación). Vuelva a estimar los datos desestacionalizados. ¿Cuál fue el efecto de ese outlier?

    ```{r}
    # Agregar un outlier manualmente (sumar 500 a una observación)
    plastics_outlier <- plastics
    plastics_outlier[15] <- plastics_outlier[15] + 500

    # Recalcular la descomposición clásica multiplicativa con los datos modificados
    decomposition_outlier <- decompose(plastics_outlier, type = "multiplicative")

    # Obtener los componentes de la descomposición con el outlier
    trend_outlier <- decomposition_outlier$trend
    seasonal_outlier <- decomposition_outlier$seasonal
    random_outlier <- decomposition_outlier$random

    # Calcular los datos desestacionalizados con el outlier
    desestacionalizado_outlier <- plastics_outlier / seasonal_outlier

    # Graficar los datos desestacionalizados con el outlier
    plot(desestacionalizado_outlier, type = "l", xlab = "Tiempo", ylab = "Datos desestacionalizados",
         main = "Datos desestacionalizados del Producto A con Outlier")

    ```

    vi) ¿Hace alguna diferencia que el outlier se encuentre cerca del final de la serie o más alrededor del centro? """ Sí, la ubicación del outlier puede influir en cómo afecta a la serie de tiempo y cómo se refleja en los datos desestacionalizados. Aquí hay algunas consideraciones:

Outlier cerca del final de la serie: Si el outlier se encuentra cerca del final de la serie de tiempo, su impacto puede ser menos notable en los datos desestacionalizados. Esto se debe a que los efectos de estacionalidad en los datos ya se han tenido en cuenta y pueden ser menos pronunciados en las observaciones más recientes. Sin embargo, si el outlier es lo suficientemente grande, aún puede tener un efecto significativo en la serie desestacionalizada.

Outlier más cerca del centro de la serie: Si el outlier está más cerca del centro de la serie de tiempo, su efecto puede ser más pronunciado en los datos desestacionalizados. Esto se debe a que los efectos de estacionalidad en los datos aún pueden ser fuertes en ese punto de la serie, y el outlier puede tener un impacto más directo en las observaciones cercanas.

En general, la ubicación del outlier puede influir en la magnitud de su efecto en la serie de tiempo y cómo se refleja en los datos desestacionalizados. Es importante tener en cuenta la ubicación del outlier al interpretar sus efectos en el análisis de la serie de tiempo. """
